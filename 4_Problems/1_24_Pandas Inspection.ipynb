{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afd62831",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/lukebarousse/Python_Data_Analytics_Course/blob/main/4_Problems/1_24_Pandas Inspection.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169fd3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/anaconda3/lib/python3.12/site-packages (3.6.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (4.66.5)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (0.32.4)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/anaconda3/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# Pandas Inspection\n",
    "# All future problems will refer to using the \"DataFrame\" which is the course dataset we loaded previously (e.g.,'lukebarousse/data_jobs').\n",
    "!pip install -U datasets\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('lukebarousse/data_jobs')\n",
    "df = dataset['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c4c666",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd73f36",
   "metadata": {},
   "source": [
    "## 🟩 Access Third Row (1.24.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bada727b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_title_short                                              Data Engineer\n",
       "job_title                Data Engineer/Scientist/Analyst, Mid or Senior...\n",
       "job_location                                               Berlin, Germany\n",
       "job_via                                                       via LinkedIn\n",
       "job_schedule_type                                                Full-time\n",
       "job_work_from_home                                                   False\n",
       "search_location                                                    Germany\n",
       "job_posted_date                                        2023-10-10 13:14:55\n",
       "job_no_degree_mention                                                False\n",
       "job_health_insurance                                                 False\n",
       "job_country                                                        Germany\n",
       "salary_rate                                                           None\n",
       "salary_year_avg                                                        NaN\n",
       "salary_hour_avg                                                        NaN\n",
       "company_name                                      ALPHA Augmented Services\n",
       "job_skills               ['python', 'sql', 'c#', 'azure', 'airflow', 'd...\n",
       "job_type_skills          {'analyst_tools': ['dax'], 'cloud': ['azure'],...\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Problem Statement:\n",
    "# Access the third row of the DataFrame using its index and display it.\n",
    "df.iloc[2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2625930f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cec3e2",
   "metadata": {},
   "source": [
    "## 🟨 Unique Job Countries (1.24.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b6bfe29b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['United States', 'Mexico', 'Germany', 'Sudan', 'Romania',\n",
       "       'Denmark', 'Switzerland', 'France', 'Brazil', 'United Kingdom',\n",
       "       'India', 'Poland', 'Belgium', 'Russia', 'Serbia', 'Singapore',\n",
       "       'Costa Rica', 'Ireland', 'Italy', 'Malaysia', 'Canada', 'Uruguay',\n",
       "       'Namibia', 'Estonia', 'Israel', 'Hungary', 'Austria',\n",
       "       'Philippines', 'Egypt', 'Australia', 'Chile', 'Spain',\n",
       "       'Netherlands', 'South Africa', 'Colombia', 'Hong Kong', 'Kuwait',\n",
       "       'Finland', 'Luxembourg', 'China', 'Puerto Rico', 'Sweden',\n",
       "       'Saudi Arabia', 'Argentina', 'Turkey', 'Panama', 'Nigeria',\n",
       "       'New Zealand', 'Ukraine', 'Jordan', 'United Arab Emirates',\n",
       "       'Armenia', 'Pakistan', 'Lesotho', 'Mauritius', 'Portugal',\n",
       "       'Bahrain', 'Taiwan', \"Côte d'Ivoire\", 'U.S. Virgin Islands',\n",
       "       'Réunion', 'Kazakhstan', 'Lithuania', 'Moldova', 'Belarus',\n",
       "       'Cyprus', 'Bulgaria', 'Honduras', 'Czechia', 'Peru', 'South Korea',\n",
       "       'Malta', 'Indonesia', 'Tunisia', 'Latvia', 'Slovakia', 'Lebanon',\n",
       "       'Japan', 'Sri Lanka', 'Slovenia', 'Bangladesh', 'Greece',\n",
       "       'Ecuador', 'Oman', 'Kenya', 'Guyana', 'Vietnam', 'Norway',\n",
       "       'Senegal', 'El Salvador', 'Iceland', 'Thailand', 'Ghana',\n",
       "       'Croatia', 'Myanmar', 'Nepal', 'Morocco', 'Guadeloupe', 'Iraq',\n",
       "       'Palestine', 'Guinea', 'Albania', 'Guatemala', 'Qatar', 'Uganda',\n",
       "       'Bolivia', None, 'Dominican Republic', 'Ethiopia', 'Haiti',\n",
       "       'Uzbekistan', 'Bahamas', 'Liberia', 'Montenegro', 'Cayman Islands',\n",
       "       'Mongolia', 'Macedonia (FYROM)', 'Azerbaijan', 'Burkina Faso',\n",
       "       'Guam', 'Trinidad and Tobago', 'Benin', 'Kyrgyzstan',\n",
       "       'Bosnia and Herzegovina', 'Zambia', 'Cameroon', 'Venezuela',\n",
       "       'Barbados', 'Togo', 'Rwanda', 'Cambodia', 'Algeria', 'Afghanistan',\n",
       "       'Congo, Democratic Republic of the', 'Zimbabwe', 'Jamaica',\n",
       "       'Suriname', 'Mozambique', 'Yemen', 'Tanzania', 'Madagascar',\n",
       "       'Mali', 'Paraguay', 'Brunei', 'Malawi', 'Nicaragua', 'Libya',\n",
       "       'Tajikistan', 'Mauritania', 'Botswana', 'Fiji',\n",
       "       'Northern Mariana Islands', 'Angola', 'Somalia',\n",
       "       'Papua New Guinea', 'Gambia', 'Djibouti', 'Laos', 'Curaçao',\n",
       "       'Maldives', 'Bhutan'], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Problem Statement:\n",
    "# Display the unique values in the job_country column.\n",
    "df.job_country.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20de2ec6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98da3ceb",
   "metadata": {},
   "source": [
    "## 🟨 Filter by Job Schedule Type and Display (1.24.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10295ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title_short</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_via</th>\n",
       "      <th>job_schedule_type</th>\n",
       "      <th>job_work_from_home</th>\n",
       "      <th>search_location</th>\n",
       "      <th>job_posted_date</th>\n",
       "      <th>job_no_degree_mention</th>\n",
       "      <th>job_health_insurance</th>\n",
       "      <th>job_country</th>\n",
       "      <th>salary_rate</th>\n",
       "      <th>salary_year_avg</th>\n",
       "      <th>salary_hour_avg</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_skills</th>\n",
       "      <th>job_type_skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Senior Clinical Data Engineer / Principal Clin...</td>\n",
       "      <td>Watertown, CT</td>\n",
       "      <td>via Work Nearby</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Texas, United States</td>\n",
       "      <td>2023-06-16 13:44:15</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boehringer Ingelheim</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Guadalajara, Jalisco, Mexico</td>\n",
       "      <td>via BeBee México</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>2023-01-14 13:18:07</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hewlett Packard Enterprise</td>\n",
       "      <td>['r', 'python', 'sql', 'nosql', 'power bi', 't...</td>\n",
       "      <td>{'analyst_tools': ['power bi', 'tableau'], 'pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Data Engineer/Scientist/Analyst, Mid or Senior...</td>\n",
       "      <td>Berlin, Germany</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2023-10-10 13:14:55</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ALPHA Augmented Services</td>\n",
       "      <td>['python', 'sql', 'c#', 'azure', 'airflow', 'd...</td>\n",
       "      <td>{'analyst_tools': ['dax'], 'cloud': ['azure'],...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        job_title_short                                          job_title  \\\n",
       "0  Senior Data Engineer  Senior Clinical Data Engineer / Principal Clin...   \n",
       "1          Data Analyst                                       Data Analyst   \n",
       "2         Data Engineer  Data Engineer/Scientist/Analyst, Mid or Senior...   \n",
       "\n",
       "                   job_location           job_via job_schedule_type  \\\n",
       "0                 Watertown, CT   via Work Nearby         Full-time   \n",
       "1  Guadalajara, Jalisco, Mexico  via BeBee México         Full-time   \n",
       "2               Berlin, Germany      via LinkedIn         Full-time   \n",
       "\n",
       "   job_work_from_home       search_location      job_posted_date  \\\n",
       "0               False  Texas, United States  2023-06-16 13:44:15   \n",
       "1               False                Mexico  2023-01-14 13:18:07   \n",
       "2               False               Germany  2023-10-10 13:14:55   \n",
       "\n",
       "   job_no_degree_mention  job_health_insurance    job_country salary_rate  \\\n",
       "0                  False                 False  United States        None   \n",
       "1                  False                 False         Mexico        None   \n",
       "2                  False                 False        Germany        None   \n",
       "\n",
       "   salary_year_avg  salary_hour_avg                company_name  \\\n",
       "0              NaN              NaN        Boehringer Ingelheim   \n",
       "1              NaN              NaN  Hewlett Packard Enterprise   \n",
       "2              NaN              NaN    ALPHA Augmented Services   \n",
       "\n",
       "                                          job_skills  \\\n",
       "0                                               None   \n",
       "1  ['r', 'python', 'sql', 'nosql', 'power bi', 't...   \n",
       "2  ['python', 'sql', 'c#', 'azure', 'airflow', 'd...   \n",
       "\n",
       "                                     job_type_skills  \n",
       "0                                               None  \n",
       "1  {'analyst_tools': ['power bi', 'tableau'], 'pr...  \n",
       "2  {'analyst_tools': ['dax'], 'cloud': ['azure'],...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Problem Statement:\n",
    "# Display the first 3 rows of the DataFrame where the job_schedule_type is 'Full-time'.\n",
    "df[df.job_schedule_type == 'Full-time'].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a096207",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310c4c3b",
   "metadata": {},
   "source": [
    "## 🟥 Check Missing Values (1.24.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e8184154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title_short</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_via</th>\n",
       "      <th>job_schedule_type</th>\n",
       "      <th>job_work_from_home</th>\n",
       "      <th>search_location</th>\n",
       "      <th>job_posted_date</th>\n",
       "      <th>job_no_degree_mention</th>\n",
       "      <th>job_health_insurance</th>\n",
       "      <th>job_country</th>\n",
       "      <th>salary_rate</th>\n",
       "      <th>salary_year_avg</th>\n",
       "      <th>salary_hour_avg</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_skills</th>\n",
       "      <th>job_type_skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Guadalajara, Jalisco, Mexico</td>\n",
       "      <td>via BeBee México</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>2023-01-14 13:18:07</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hewlett Packard Enterprise</td>\n",
       "      <td>['r', 'python', 'sql', 'nosql', 'power bi', 't...</td>\n",
       "      <td>{'analyst_tools': ['power bi', 'tableau'], 'pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Data Engineer/Scientist/Analyst, Mid or Senior...</td>\n",
       "      <td>Berlin, Germany</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2023-10-10 13:14:55</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ALPHA Augmented Services</td>\n",
       "      <td>['python', 'sql', 'c#', 'azure', 'airflow', 'd...</td>\n",
       "      <td>{'analyst_tools': ['dax'], 'cloud': ['azure'],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>LEAD ENGINEER - PRINCIPAL ANALYST - PRINCIPAL ...</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>via Diversity.com</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Texas, United States</td>\n",
       "      <td>2023-07-04 13:01:41</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southwest Research Institute</td>\n",
       "      <td>['python', 'c++', 'java', 'matlab', 'aws', 'te...</td>\n",
       "      <td>{'cloud': ['aws'], 'libraries': ['tensorflow',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Data Engineer- Sr Jobs</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>via Clearance Jobs</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>2023-08-07 14:29:36</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kristina Daniel</td>\n",
       "      <td>['bash', 'python', 'oracle', 'aws', 'ansible',...</td>\n",
       "      <td>{'cloud': ['oracle', 'aws'], 'other': ['ansibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>GCP Data Engineer</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>via ZipRecruiter</td>\n",
       "      <td>Contractor and Temp work</td>\n",
       "      <td>True</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>2023-11-07 14:01:59</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>smart folks inc</td>\n",
       "      <td>['python', 'sql', 'gcp']</td>\n",
       "      <td>{'cloud': ['gcp'], 'programming': ['python', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785736</th>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>DevOps Engineer</td>\n",
       "      <td>Singapura</td>\n",
       "      <td>melalui Trabajo.org</td>\n",
       "      <td>Pekerjaan tetap</td>\n",
       "      <td>False</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>2023-03-13 06:16:16</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CAREERSTAR INTERNATIONAL PTE. LTD.</td>\n",
       "      <td>['bash', 'python', 'perl', 'linux', 'unix', 'k...</td>\n",
       "      <td>{'os': ['linux', 'unix'], 'other': ['kubernete...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785737</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>CRM Data Analyst</td>\n",
       "      <td>Bad Rodach, Jerman</td>\n",
       "      <td>melalui BeBee Deutschland</td>\n",
       "      <td>Pekerjaan tetap</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2023-03-12 06:18:18</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HABA FAMILYGROUP</td>\n",
       "      <td>['sas', 'sas', 'sql', 'excel']</td>\n",
       "      <td>{'analyst_tools': ['sas', 'excel'], 'programmi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785738</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Commercial Analyst - Start Now</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>melalui Ricebowl</td>\n",
       "      <td>Pekerjaan tetap</td>\n",
       "      <td>False</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>2023-03-12 06:32:36</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lendlease Corporation</td>\n",
       "      <td>['powerpoint', 'excel']</td>\n",
       "      <td>{'analyst_tools': ['powerpoint', 'excel']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785739</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Principal Associate, Data Engineer (Remote-Eli...</td>\n",
       "      <td>Newark, New Jersey, Amerika Serikat</td>\n",
       "      <td>melalui Recruit.net</td>\n",
       "      <td>Pekerjaan tetap</td>\n",
       "      <td>False</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>2023-03-12 06:32:15</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Capital One</td>\n",
       "      <td>['python', 'go', 'nosql', 'sql', 'mongo', 'she...</td>\n",
       "      <td>{'cloud': ['aws', 'snowflake', 'azure', 'redsh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785740</th>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>AWS System Analyst</td>\n",
       "      <td>India</td>\n",
       "      <td>melalui Trigyn</td>\n",
       "      <td>Pekerjaan tetap</td>\n",
       "      <td>False</td>\n",
       "      <td>India</td>\n",
       "      <td>2023-03-13 06:16:31</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>India</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trigyn</td>\n",
       "      <td>['aws', 'flow']</td>\n",
       "      <td>{'cloud': ['aws'], 'other': ['flow']}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>668704 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          job_title_short                                          job_title  \\\n",
       "1            Data Analyst                                       Data Analyst   \n",
       "2           Data Engineer  Data Engineer/Scientist/Analyst, Mid or Senior...   \n",
       "3           Data Engineer  LEAD ENGINEER - PRINCIPAL ANALYST - PRINCIPAL ...   \n",
       "4           Data Engineer                             Data Engineer- Sr Jobs   \n",
       "5           Data Engineer                                  GCP Data Engineer   \n",
       "...                   ...                                                ...   \n",
       "785736  Software Engineer                                    DevOps Engineer   \n",
       "785737       Data Analyst                                   CRM Data Analyst   \n",
       "785738   Business Analyst                     Commercial Analyst - Start Now   \n",
       "785739      Data Engineer  Principal Associate, Data Engineer (Remote-Eli...   \n",
       "785740  Software Engineer                                 AWS System Analyst   \n",
       "\n",
       "                               job_location                    job_via  \\\n",
       "1              Guadalajara, Jalisco, Mexico           via BeBee México   \n",
       "2                           Berlin, Germany               via LinkedIn   \n",
       "3                           San Antonio, TX          via Diversity.com   \n",
       "4                            Washington, DC         via Clearance Jobs   \n",
       "5                                  Anywhere           via ZipRecruiter   \n",
       "...                                     ...                        ...   \n",
       "785736                            Singapura        melalui Trabajo.org   \n",
       "785737                   Bad Rodach, Jerman  melalui BeBee Deutschland   \n",
       "785738                             Malaysia           melalui Ricebowl   \n",
       "785739  Newark, New Jersey, Amerika Serikat        melalui Recruit.net   \n",
       "785740                                India             melalui Trigyn   \n",
       "\n",
       "               job_schedule_type  job_work_from_home       search_location  \\\n",
       "1                      Full-time               False                Mexico   \n",
       "2                      Full-time               False               Germany   \n",
       "3                      Full-time               False  Texas, United States   \n",
       "4                      Full-time               False                 Sudan   \n",
       "5       Contractor and Temp work                True               Georgia   \n",
       "...                          ...                 ...                   ...   \n",
       "785736           Pekerjaan tetap               False             Singapore   \n",
       "785737           Pekerjaan tetap               False               Germany   \n",
       "785738           Pekerjaan tetap               False              Malaysia   \n",
       "785739           Pekerjaan tetap               False                 Sudan   \n",
       "785740           Pekerjaan tetap               False                 India   \n",
       "\n",
       "            job_posted_date  job_no_degree_mention  job_health_insurance  \\\n",
       "1       2023-01-14 13:18:07                  False                 False   \n",
       "2       2023-10-10 13:14:55                  False                 False   \n",
       "3       2023-07-04 13:01:41                   True                 False   \n",
       "4       2023-08-07 14:29:36                  False                 False   \n",
       "5       2023-11-07 14:01:59                  False                 False   \n",
       "...                     ...                    ...                   ...   \n",
       "785736  2023-03-13 06:16:16                  False                 False   \n",
       "785737  2023-03-12 06:18:18                  False                 False   \n",
       "785738  2023-03-12 06:32:36                  False                 False   \n",
       "785739  2023-03-12 06:32:15                  False                 False   \n",
       "785740  2023-03-13 06:16:31                  False                 False   \n",
       "\n",
       "          job_country salary_rate  salary_year_avg  salary_hour_avg  \\\n",
       "1              Mexico        None              NaN              NaN   \n",
       "2             Germany        None              NaN              NaN   \n",
       "3       United States        None              NaN              NaN   \n",
       "4               Sudan        None              NaN              NaN   \n",
       "5       United States        None              NaN              NaN   \n",
       "...               ...         ...              ...              ...   \n",
       "785736      Singapore        None              NaN              NaN   \n",
       "785737        Germany        None              NaN              NaN   \n",
       "785738       Malaysia        None              NaN              NaN   \n",
       "785739          Sudan        None              NaN              NaN   \n",
       "785740          India        None              NaN              NaN   \n",
       "\n",
       "                              company_name  \\\n",
       "1               Hewlett Packard Enterprise   \n",
       "2                 ALPHA Augmented Services   \n",
       "3             Southwest Research Institute   \n",
       "4                          Kristina Daniel   \n",
       "5                          smart folks inc   \n",
       "...                                    ...   \n",
       "785736  CAREERSTAR INTERNATIONAL PTE. LTD.   \n",
       "785737                    HABA FAMILYGROUP   \n",
       "785738               Lendlease Corporation   \n",
       "785739                         Capital One   \n",
       "785740                              Trigyn   \n",
       "\n",
       "                                               job_skills  \\\n",
       "1       ['r', 'python', 'sql', 'nosql', 'power bi', 't...   \n",
       "2       ['python', 'sql', 'c#', 'azure', 'airflow', 'd...   \n",
       "3       ['python', 'c++', 'java', 'matlab', 'aws', 'te...   \n",
       "4       ['bash', 'python', 'oracle', 'aws', 'ansible',...   \n",
       "5                                ['python', 'sql', 'gcp']   \n",
       "...                                                   ...   \n",
       "785736  ['bash', 'python', 'perl', 'linux', 'unix', 'k...   \n",
       "785737                     ['sas', 'sas', 'sql', 'excel']   \n",
       "785738                            ['powerpoint', 'excel']   \n",
       "785739  ['python', 'go', 'nosql', 'sql', 'mongo', 'she...   \n",
       "785740                                    ['aws', 'flow']   \n",
       "\n",
       "                                          job_type_skills  \n",
       "1       {'analyst_tools': ['power bi', 'tableau'], 'pr...  \n",
       "2       {'analyst_tools': ['dax'], 'cloud': ['azure'],...  \n",
       "3       {'cloud': ['aws'], 'libraries': ['tensorflow',...  \n",
       "4       {'cloud': ['oracle', 'aws'], 'other': ['ansibl...  \n",
       "5       {'cloud': ['gcp'], 'programming': ['python', '...  \n",
       "...                                                   ...  \n",
       "785736  {'os': ['linux', 'unix'], 'other': ['kubernete...  \n",
       "785737  {'analyst_tools': ['sas', 'excel'], 'programmi...  \n",
       "785738         {'analyst_tools': ['powerpoint', 'excel']}  \n",
       "785739  {'cloud': ['aws', 'snowflake', 'azure', 'redsh...  \n",
       "785740              {'cloud': ['aws'], 'other': ['flow']}  \n",
       "\n",
       "[668704 rows x 17 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Problem Statement:\n",
    "# Check for missing values in the job_skills column and display the rows where the values are not NA.\n",
    "df[df.job_skills.notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d9297c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e145c4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已处理第 1 页，找到 20 篇文章\n",
      "数据已保存到 google_scholar_articles.csv\n",
      "\n",
      "前5篇文章信息预览:\n",
      "\n",
      "文章 1:\n",
      "标题: Ultrafast dynamics of excitons in tetracene single crystals\n",
      "期刊: The Journal of Chemical Physics 140 (11)\n",
      "年份: 2014\n",
      "被引次数: 59\n",
      "\n",
      "文章 2:\n",
      "标题: Application of Raman spectroscopy in type 2 diabetes screening in blood using leucine and isoleucine amino-acids as biomarkers and in comparative anti-diabetic drugs efficacy …\n",
      "期刊: PLoS One 12 (9)\n",
      "年份: 2017\n",
      "被引次数: 49\n",
      "\n",
      "文章 3:\n",
      "标题: Ultrasensitive detection of plant hormone abscisic acid-based surface-enhanced Raman spectroscopy aptamer sensor\n",
      "期刊: Analytical and Bioanalytical Chemistry 414 (8)\n",
      "年份: 2022\n",
      "被引次数: 27\n",
      "\n",
      "文章 4:\n",
      "标题: A multi-channel localized surface plasmon resonance system for absorptiometric determination of abscisic acid by using gold nanoparticles functionalized with a polyadenine …\n",
      "期刊: Microchimica Acta 187\n",
      "年份: 2020\n",
      "被引次数: 24\n",
      "\n",
      "文章 5:\n",
      "标题: Effect of crusting operations on the physical properties of leather\n",
      "期刊: \n",
      "年份: N/A\n",
      "被引次数: 22\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from typing import List, Dict\n",
    "import csv\n",
    "from time import sleep\n",
    "\n",
    "def scrape_google_scholar_profile(profile_url: str, max_pages: int = None) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    爬取Google Scholar个人主页的文章信息\n",
    "    \n",
    "    参数:\n",
    "        profile_url: Google Scholar个人主页URL\n",
    "        max_pages: 最大爬取页数(可选)\n",
    "    \n",
    "    返回:\n",
    "        包含文章信息的字典列表\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    \n",
    "    articles = []\n",
    "    page_num = 1\n",
    "    while True:\n",
    "        # 构造分页URL\n",
    "        if \"?user=\" in profile_url and \"&\" not in profile_url:\n",
    "            page_url = f\"{profile_url}&page={page_num}\"\n",
    "        else:\n",
    "            page_url = f\"{profile_url}?page={page_num}\"\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(page_url, headers=headers)\n",
    "            response.raise_for_status()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"请求失败: {e}\")\n",
    "            break\n",
    "        \n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # 检查是否到达最后一页\n",
    "        if \"There are no articles in this profile.\" in response.text:\n",
    "            break\n",
    "        \n",
    "        # 提取文章条目\n",
    "        entries = soup.find_all('tr', class_='gsc_a_tr')\n",
    "        if not entries:\n",
    "            break\n",
    "            \n",
    "        for entry in entries:\n",
    "            article = {}\n",
    "            \n",
    "            # 文章标题\n",
    "            title_elem = entry.find('a', class_='gsc_a_at')\n",
    "            article['title'] = title_elem.text if title_elem else \"N/A\"\n",
    "            \n",
    "            # 作者和期刊信息\n",
    "            authors_journal_elem = entry.find('div', class_='gs_gray')\n",
    "            article['authors_journal'] = authors_journal_elem.text if authors_journal_elem else \"N/A\"\n",
    "            \n",
    "            # 分离期刊名称和年份\n",
    "            journal_year = \"\"\n",
    "            journal_elem = entry.find_all('div', class_='gs_gray')[-1]\n",
    "            if journal_elem:\n",
    "                journal_year = journal_elem.text\n",
    "            \n",
    "            # 尝试从journal_year中提取期刊和年份\n",
    "            journal_parts = journal_year.split(',')\n",
    "            if len(journal_parts) >= 2:\n",
    "                article['journal'] = journal_parts[0].strip()\n",
    "                article['year'] = journal_parts[-1].strip()\n",
    "            else:\n",
    "                article['journal'] = journal_year.strip()\n",
    "                article['year'] = \"N/A\"\n",
    "            \n",
    "            # 被引次数\n",
    "            citations_elem = entry.find('a', class_='gsc_a_ac')\n",
    "            if citations_elem and citations_elem.text.strip():\n",
    "                article['citations'] = int(citations_elem.text.strip())\n",
    "            else:\n",
    "                article['citations'] = 0\n",
    "            \n",
    "            articles.append(article)\n",
    "        \n",
    "        print(f\"已处理第 {page_num} 页，找到 {len(articles)} 篇文章\")\n",
    "        \n",
    "        # 检查是否还有下一页\n",
    "        next_button = soup.find('button', id='gsc_bpf_next')\n",
    "        if not next_button or 'disabled' in next_button.attrs:\n",
    "            break\n",
    "        \n",
    "        # 检查是否达到最大页数限制\n",
    "        if max_pages and page_num >= max_pages:\n",
    "            break\n",
    "            \n",
    "        page_num += 1\n",
    "        sleep(2)  # 礼貌性延迟，避免被封\n",
    "    \n",
    "    return articles\n",
    "\n",
    "def save_to_csv(articles: List[Dict], filename: str = 'google_scholar_articles.csv'):\n",
    "    \"\"\"\n",
    "    将文章信息保存到CSV文件\n",
    "    \n",
    "    参数:\n",
    "        articles: 文章信息列表\n",
    "        filename: 输出文件名\n",
    "    \"\"\"\n",
    "    if not articles:\n",
    "        print(\"没有文章数据可保存\")\n",
    "        return\n",
    "    \n",
    "    keys = articles[0].keys()\n",
    "    \n",
    "    with open(filename, 'w', newline='', encoding='utf-8-sig') as output_file:\n",
    "        dict_writer = csv.DictWriter(output_file, fieldnames=keys)\n",
    "        dict_writer.writeheader()\n",
    "        dict_writer.writerows(articles)\n",
    "    \n",
    "    print(f\"数据已保存到 {filename}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 使用示例\n",
    "    profile_url = input(\"请输入Google Scholar个人主页URL: \")\n",
    "    max_pages = input(\"请输入最大爬取页数(留空则爬取所有): \")\n",
    "    \n",
    "    try:\n",
    "        max_pages = int(max_pages) if max_pages else None\n",
    "    except ValueError:\n",
    "        print(\"输入的不是有效数字，将爬取所有页面\")\n",
    "        max_pages = None\n",
    "    \n",
    "    articles = scrape_google_scholar_profile(profile_url, max_pages)\n",
    "    \n",
    "    if articles:\n",
    "        save_to_csv(articles)\n",
    "        print(\"\\n前5篇文章信息预览:\")\n",
    "        for i, article in enumerate(articles[:5]):\n",
    "            print(f\"\\n文章 {i+1}:\")\n",
    "            print(f\"标题: {article['title']}\")\n",
    "            print(f\"期刊: {article['journal']}\")\n",
    "            print(f\"年份: {article['year']}\")\n",
    "            print(f\"被引次数: {article['citations']}\")\n",
    "    else:\n",
    "        print(\"没有找到文章信息\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934fb347",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
